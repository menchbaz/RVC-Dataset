import os import gradio as gr import yt_dlp import librosa import soundfile as sf import noisereduce as nr import numpy as np from scipy.signal import butter, filtfilt from pydub import AudioSegment from pydub.silence import split_on_silence

def setup_directories(): os.makedirs('temp', exist_ok=True) os.makedirs('models', exist_ok=True) os.makedirs('output', exist_ok=True)

def download_model(): if not os.path.exists('models/drumsep.th'): os.system('aria2c https://huggingface.co/Eddycrack864/Drumsep/resolve/main/modelo_final.th -o models/drumsep.th')

def download_youtube_audio(url): ydl_opts = { 'format': 'bestaudio/best', 'postprocessors': [{ 'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192', }], 'outtmpl': os.path.join('temp', '%(title)s.%(ext)s'), 'restrictfilenames': True } with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([url]) return [os.path.join('temp', f) for f in os.listdir('temp') if f.endswith('.wav')]

def separate_audio(url_or_files, model_choice): try: if isinstance(url_or_files, str) and url_or_files.startswith('http'): input_files = download_youtube_audio(url_or_files) else: input_files = [f.name for f in url_or_files]

if not input_files:
        return "Ø®Ø·Ø§: Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒâ€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!"

    models = {
        'BS-Roformer-1297': 'model_bs_roformer_ep_317_sdr_12.9755.ckpt',
        'BS-Roformer-1296': 'model_bs_roformer_ep_368_sdr_12.9628.ckpt',
        'Mel-Roformer-1143': 'model_mel_band_roformer_ep_3005_sdr_11.4360.ckpt'
    }
    
    for file in input_files:
        os.system(f'audio-separator "{file}" --model_filename {models[model_choice]} --output_dir=output')
        if file.startswith('temp/'):
            os.remove(file)

    return "âœ… Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!"
except Exception as e:
    return f"Ø®Ø·Ø§: {str(e)}"

def combine_and_clean(use_uploaded_files, uploaded_files=None): try: audio_files = [] if not use_uploaded_files: output_files = [f for f in os.listdir('output') if 'Vocals' in f] audio_files = [os.path.join('output', f) for f in output_files] elif uploaded_files: audio_files = [f.name for f in uploaded_files]

if len(audio_files) < 2:
        return "Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù†ÛŒØ§Ø² Ø§Ø³Øª!"

    combined_audio = None
    for file in audio_files:
        audio = AudioSegment.from_file(file)
        if combined_audio is None:
            combined_audio = audio
        else:
            combined_audio += audio

    chunks = split_on_silence(
        combined_audio,
        min_silence_len=1000,
        silence_thresh=-40,
        keep_silence=100
    )

    final_audio = chunks[0]
    for chunk in chunks[1:]:
        final_audio += chunk

    output_path = "output/combined_vocals.wav"
    final_audio.export(output_path, format="wav")
    return output_path
except Exception as e:
    return f"Ø®Ø·Ø§: {str(e)}"

def process_audio(echo_reduction=0.9, presence=0.1): try: input_path = "output/combined_vocals.wav" if not os.path.exists(input_path): return "Ù„Ø·ÙØ§ Ø§Ø¨ØªØ¯Ø§ Ø§Ø² Ø¨Ø®Ø´ ØªØ±Ú©ÛŒØ¨ ØµØ¯Ø§Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"

audio, sr = librosa.load(input_path, sr=44100, mono=True)
    echo_reduced = nr.reduce_noise(
        y=audio, sr=sr, prop_decrease=echo_reduction,
        stationary=False, n_fft=2048, win_length=2048, n_std_thresh_stationary=1.2
    )
    
    b1, a1 = butter(2, [200/22050, 8000/22050], btype='band')
    b2, a2 = butter(2, 4000/22050, btype='high')
    
    filtered = filtfilt(b1, a1, echo_reduced)
    high_freq = filtfilt(b2, a2, echo_reduced) * 0.2
    enhanced = filtered + (high_freq * presence)
    
    final_audio = librosa.util.normalize(enhanced) * 0.95
    output_path = "output/final_processed.wav"
    sf.write(output_path, final_audio, sr, 'PCM_24')
    return output_path
except Exception as e:
    return f"Ø®Ø·Ø§: {str(e)}"

setup_directories() download_model()

with gr.Blocks(title="Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØµØ¯Ø§") as app: gr.Markdown("# ğŸµ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØµØ¯Ø§") with gr.Tab("Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ ØµØ¯Ø§"): url_input = gr.Textbox(label="Ù„ÛŒÙ†Ú© ÙˆÛŒØ¯ÛŒÙˆ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)") file_input = gr.File(file_count="multiple", label="Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)") model_choice = gr.Dropdown( choices=["BS-Roformer-1297", "BS-Roformer-1296", "Mel-Roformer-1143"], label="Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„", value="BS-Roformer-1297" ) separate_button = gr.Button("Ø´Ø±ÙˆØ¹ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ") separate_output = gr.Textbox(label="Ù†ØªÛŒØ¬Ù‡") separate_button.click(separate_audio, [url_input, file_input, model_choice], separate_output)

with gr.Tab("ØªØ±Ú©ÛŒØ¨ ØµØ¯Ø§Ù‡Ø§"):
    use_uploaded = gr.Checkbox(label="Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ÛŒ", value=False)
    audio_files = gr.File(file_count="multiple", label="Ø§Ù†ØªØ®Ø§Ø¨ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ")
    combine_button = gr.Button("ØªØ±Ú©ÛŒØ¨ Ùˆ Ø­Ø°Ù Ø³Ú©ÙˆØª")
    combined_output = gr.Audio(label="Ø®Ø±ÙˆØ¬ÛŒ")
    combine_button.click(combine_and_clean, [use_uploaded, audio_files], combined_output)

with gr.Tab("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ"):
    echo_slider = gr.Slider(0.7, 0.95, 0.9, label="Ù…ÛŒØ²Ø§Ù† Ø­Ø°Ù Ø§Ú©Ùˆ")
    presence_slider = gr.Slider(0.1, 0.3, 0.1, label="Ù…ÛŒØ²Ø§Ù† Ø­Ø¶ÙˆØ± ØµØ¯Ø§")
    process_button = gr.Button("Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´")
    final_output = gr.Audio(label="Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
    process_button.click(process_audio, [echo_slider, presence_slider], final_output)

if name == "main": app.launch(share=True)

